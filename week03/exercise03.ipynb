{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86627cef-7ff0-4e79-aae5-5c108bd981a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Engineering - Assignment 03: JSON Parsing\n",
    "## Parsing Healthcare Price Transparency Data\n",
    "\n",
    "**Author:** Greg Sullivan\n",
    "**Course:** DATA 5035 - Data Engineering\n",
    "\n",
    "### Objective\n",
    "Parse nested JSON healthcare data from United Health Services and flatten it into a tabular format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c255761e-26e2-4656-8931-ec419600a978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "# Once again, took me a while to figure how to access this file.  Actually,\n",
    "# my challcnge was more about where to place the file.  I eventually \n",
    "# figured that out and it worked!\n",
    "json_path = \"/Volumes/workspace/default/data_files/negotiated_rates.json\"\n",
    "\n",
    "# I'm new to Spark, so rough coding to follow.  \n",
    "# I'm sure there is a better way to do this.\n",
    "# I'm also sure there is a better way to do the explode and cast.  \n",
    "# I'm just not sure how to do it, but here we go...\n",
    "#\n",
    "# multiline accounts for the nesting of lines within lines\n",
    "# - a deeply nested data structure\n",
    "df_raw = spark.read.option(\"multiline\", \"true\").json(json_path)\n",
    "\n",
    "print(\"Schema of raw JSON:\")\n",
    "df_raw.printSchema()\n",
    "display(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c02728-f4d9-4743-a4c4-8ae2ffd77941",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "For each array element of the out_of_network array, we create a new row.\n",
    "Then, we extract the fields from each item:\n",
    "\n",
    "  name - billing item name\n",
    "  billing_code_type - CPT or HCPCS\n",
    "  billing_code - the actual code\n",
    "  description - what the code means\n",
    "  allowed_amounts - still nested! We'll explode this next\n",
    "\n",
    "This yields 6 rows (one per billing item), but allowed_amounts is still an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19a71905-d0bc-4c60-b005-d0977ecdcc4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Will try the Explode capability from Spark\n",
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "# Explode the out_of_network array\n",
    "df_items = (df_raw\n",
    "    .select(explode(col(\"out_of_network\")).alias(\"item\"))\n",
    "    .select(\n",
    "        col(\"item.name\").alias(\"name\"),\n",
    "        col(\"item.billing_code_type\").alias(\"billing_code_type\"),\n",
    "        col(\"item.billing_code\").alias(\"billing_code\"),\n",
    "        col(\"item.description\").alias(\"description\"),\n",
    "        col(\"item.allowed_amounts\").alias(\"allowed_amounts\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Number of billing items: {df_items.count()}\")\n",
    "display(df_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37420359-2508-4ebe-b106-bc82a60feb75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, we take each of the 6 rows from the prior cell\n",
    "We \"explode\" as each billing item might have multiple allowed amounts\n",
    "  (different rates for different service codes)\n",
    "For example, \"97140\" has 2 allowed amounts (service codes \"11\" and \"12\")\n",
    "\n",
    "Extracts:\n",
    "  service_code - identifies type of service (like location: office vs hospital)\n",
    "  billing_class - professional vs institutional\n",
    "  allowed_amount - the negotiated rate\n",
    "  providers - still an array! We'll explode this next\n",
    "\n",
    "This results in more rows now (some billing items had multiple allowed amounts), \n",
    "but providers is still an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "892542c5-dbac-49e3-a596-d08485f9de48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explode allowed_amounts array\n",
    "df_amounts = (df_items\n",
    "    .select(\n",
    "        col(\"name\"),\n",
    "        col(\"billing_code_type\"),\n",
    "        col(\"billing_code\"),\n",
    "        col(\"description\"),\n",
    "        explode(col(\"allowed_amounts\")).alias(\"amount_detail\")\n",
    "    )\n",
    "    .select(\n",
    "        col(\"name\"),\n",
    "        col(\"billing_code_type\"),\n",
    "        col(\"billing_code\"),\n",
    "        col(\"description\"),\n",
    "        col(\"amount_detail.service_code\").alias(\"service_code\"),\n",
    "        col(\"amount_detail.billing_class\").alias(\"billing_class\"),\n",
    "        col(\"amount_detail.payments.allowed_amount\").alias(\"allowed_amount\"),\n",
    "        col(\"amount_detail.payments.providers\").alias(\"providers\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Number of allowed amount records: {df_amounts.count()}\")\n",
    "display(df_amounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5e53cd0-abe4-4410-bf87-ff75fb7cfc05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here is our third explosion\n",
    "It takes each row from the prior cell\n",
    "  explode(col(\"providers\")) - Each allowed amount might apply to multiple providers\n",
    "\n",
    "Then, we extract:\n",
    "  billed_charge - what the provider actually charges (before negotiation)\n",
    "  npi_array - still an array! One more explosion to go\n",
    "\n",
    "This results in even MORE rows\n",
    "  one per provider per allowed amount, but npi_array is still an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "546b0ac3-cb2a-4c9c-b0b7-310d151035f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explode providers array\n",
    "df_providers = (df_amounts\n",
    "    .select(\n",
    "        col(\"name\"),\n",
    "        col(\"billing_code_type\"),\n",
    "        col(\"billing_code\"),\n",
    "        col(\"description\"),\n",
    "        col(\"service_code\"),\n",
    "        col(\"billing_class\"),\n",
    "        col(\"allowed_amount\"),\n",
    "        explode(col(\"providers\")).alias(\"provider_detail\")\n",
    "    )\n",
    "    .select(\n",
    "        col(\"name\"),\n",
    "        col(\"billing_code_type\"),\n",
    "        col(\"billing_code\"),\n",
    "        col(\"description\"),\n",
    "        col(\"service_code\"),\n",
    "        col(\"billing_class\"),\n",
    "        col(\"allowed_amount\"),\n",
    "        col(\"provider_detail.billed_charge\").alias(\"billed_charge\"),\n",
    "        col(\"provider_detail.npi\").alias(\"npi_array\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Number of provider records: {df_providers.count()}\")\n",
    "display(df_providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3759057b-bfd1-47a1-95c3-898e597b6589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now, take each of the newly created rows from prior explosion\n",
    "  explode(col(\"npi_array\")) accounting for the possibility that \n",
    "    each provider record might have multiple NPIs (National Provider Identifiers)\n",
    "\n",
    "I note NPI is a double (all .0).  So, I recast as bigint to make it clear integer\n",
    "\n",
    "This yields the individual NPI numbers\n",
    "\n",
    "Voila!  Our Final flat table! \n",
    "  No more arrays. Every single nested element is now its own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "229c02df-d029-4bd4-9cc3-e1728d302cfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explode npi array and cast to bigint\n",
    "df_final = (df_providers\n",
    "    .select(\n",
    "        col(\"name\"),\n",
    "        col(\"billing_code_type\"),\n",
    "        col(\"billing_code\"),\n",
    "        col(\"description\"),\n",
    "        col(\"service_code\"),\n",
    "        col(\"billing_class\"),\n",
    "        col(\"allowed_amount\"),\n",
    "        col(\"billed_charge\"),\n",
    "        explode(col(\"npi_array\")).alias(\"npi\")\n",
    "    )\n",
    "    .withColumn(\"npi\", col(\"npi\").cast(\"bigint\"))\n",
    ")\n",
    "\n",
    "print(f\"Final flattened records: {df_final.count()}\")\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9f9ff90-cd00-4568-8da7-ab11b84bb7b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's confirm we have the right structure\n",
    "\n",
    "printSchema() - Shows the data types of each column\n",
    "show() - Displays first 5 rows as a table\n",
    "\n",
    "Do our columns match what we were looking for?  YES\n",
    "\n",
    "This confirms we have the right structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e97a2296-4e92-44d8-b0d0-ec330a58ff5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify schema\n",
    "print(\"Final Schema:\")\n",
    "df_final.printSchema()\n",
    "\n",
    "# Show sample\n",
    "df_final.show(5, truncate=False)\n",
    "\n",
    "# Verify columns match expected format\n",
    "expected_columns = ['name', 'billing_code_type', 'billing_code', 'description', \n",
    "                   'service_code', 'billing_class', 'allowed_amount', 'billed_charge', 'npi']\n",
    "print(f\"\\nColumns match expected: {df_final.columns == expected_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb7cf93e-e410-4c97-9ba2-14f06fd47249",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "I'll show some summary stats not just for verification,\n",
    "  but also clarification\n",
    "\n",
    "count the unique billing codes (how many different procedures)\n",
    "count the unique NPIs (how many different providers)\n",
    "group by billing code type (CPT vs HCPCS)\n",
    "show stats on dollar amounts (min, max, average, etc.)\n",
    "\n",
    "This gives us insights about the data we just flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a04925be-41e1-4a35-baeb-6227ee1761d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Unique billing codes:\", df_final.select(\"billing_code\").distinct().count())\n",
    "print(\"Unique NPIs:\", df_final.select(\"npi\").distinct().count())\n",
    "\n",
    "print(\"\\nBilling Code Type Distribution:\")\n",
    "df_final.groupBy(\"billing_code_type\").count().show()\n",
    "\n",
    "print(\"\\nAmount Statistics:\")\n",
    "df_final.select(\"allowed_amount\", \"billed_charge\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6502fd4-b3bc-4122-9af8-cc8ae83b3438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Concluding Remarks\n",
    "\n",
    "This was all done with a small number of lines of code, which \n",
    "makes me curious about the full power or Spark in this use case.\n",
    "I see how useful this can be in multi-layer nested data sets, but\n",
    "also for very large data sets (nested or not).  I look forward\n",
    "to learning more about using Spark.\n",
    "\n",
    "No wonder it's nearly impossible to understand medical bills!!!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "exercise03",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
